from fastapi import APIRouter, HTTPException, UploadFile, File, Form, Body
from fastapi.responses import FileResponse
from schemas.essays import EssayAnalysisResponse
from services.excel_service import EssayTopicService
from services.ai_service import AIService
from services.image_service import ImageService
from config import TOPICS_DIR
from pathlib import Path
import json
from datetime import datetime
from typing import Dict, Any

router = APIRouter()
topic_service = EssayTopicService()
ai_service = AIService()
image_service = ImageService()

@router.get("/essays/topics")
def get_topics():
    """è·å–æ‰€æœ‰å¯ç”¨çš„å¹´ä»½å’Œä½œæ–‡ç±»å‹"""
    try:
        years = topic_service.get_all_years()
        essay_types = topic_service.get_essay_types()
        return {"years": years, "essay_types": essay_types}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/essays/topics")
async def add_topic(
    year: int = Form(...),
    essay_type: str = Form(...),
    topic_image: UploadFile = File(...),
    reference: str = Form(...)
):
    """æ·»åŠ ä½œæ–‡é¢˜ç›®"""
    try:
        # ä¿å­˜é¢˜ç›®å›¾ç‰‡
        image_content = await topic_image.read()
        # å°†ä¸­æ–‡ä½œæ–‡ç±»å‹è½¬æ¢ä¸ºè‹±æ–‡ï¼Œé¿å…æ–‡ä»¶åä¸­å‡ºç°ä¸­æ–‡
        essay_type_short = "small" if essay_type == "å°ä½œæ–‡" else "large"
        filename = f"topic_{year}_{essay_type_short}_{datetime.now().strftime('%Y%m%d%H%M%S')}.jpg"
        
        # ä¿å­˜åˆ°topicsç›®å½•
        file_path = TOPICS_DIR / filename
        with open(file_path, 'wb') as f:
            f.write(image_content)
        
        # å­˜å‚¨ç›¸å¯¹è·¯å¾„
        relative_path = f"data/topics/{filename}"
        
        # æ·»åŠ åˆ°æ•°æ®åº“
        topic_service.add_topic(year, essay_type, relative_path, reference)
        
        return {"message": "é¢˜ç›®æ·»åŠ æˆåŠŸ", "image_path": relative_path}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/essays/topics/{year}/{essay_type}")
def get_topic_detail(year: int, essay_type: str):
    """è·å–ç‰¹å®šå¹´ä»½å’Œç±»å‹çš„é¢˜ç›®è¯¦æƒ…"""
    try:
        topic_data = topic_service.get_topic_by_year_and_type(year, essay_type)
        if not topic_data:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°é¢˜ç›®")
        return topic_data
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/essays/topics/image/{year}/{essay_type}")
def get_topic_image(year: int, essay_type: str):
    """è·å–é¢˜ç›®å›¾ç‰‡"""
    try:
        topic_data = topic_service.get_topic_by_year_and_type(year, essay_type)
        if not topic_data:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°é¢˜ç›®")
        
        image_path = Path(topic_data['é¢˜ç›®å›¾ç‰‡è·¯å¾„'])
        if not image_path.exists():
            raise HTTPException(status_code=404, detail="é¢˜ç›®å›¾ç‰‡ä¸å­˜åœ¨")
        
        return FileResponse(image_path)
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.delete("/essays/topics/{year}/{essay_type}")
def delete_topic(year: int, essay_type: str):
    """åˆ é™¤ä½œæ–‡é¢˜ç›®"""
    try:
        # è·å–é¢˜ç›®æ•°æ®ä»¥åˆ é™¤å›¾ç‰‡
        topic_data = topic_service.get_topic_by_year_and_type(year, essay_type)
        if topic_data:
            # åˆ é™¤å›¾ç‰‡æ–‡ä»¶
            image_path = Path(topic_data['é¢˜ç›®å›¾ç‰‡è·¯å¾„'])
            if image_path.exists():
                image_path.unlink()
        
        # ä»æ•°æ®åº“åˆ é™¤
        topic_service.delete_topic(year, essay_type)
        
        return {"message": "é¢˜ç›®åˆ é™¤æˆåŠŸ"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/essays/ocr")
async def ocr_essay(
    year: int = Form(...),
    essay_type: str = Form(...),
    image: UploadFile = File(...)
):
    """
    ç¬¬ä¸€æ­¥ï¼šOCRè¯†åˆ«æ‰‹å†™ä½œæ–‡
    è¿”å›è¯†åˆ«å‡ºçš„æ–‡å­—
    """
    try:
        # 1. æŸ¥æ‰¾é¢˜ç›®å’ŒèŒƒæ–‡ï¼ˆç”¨äºè¿”å›ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼‰
        topic_data = topic_service.get_topic_by_year_and_type(year, essay_type)
        if not topic_data:
            raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ°{year}å¹´{essay_type}çš„ä½œæ–‡é¢˜ç›®")
        
        # 2. ä¿å­˜ä¸Šä¼ çš„å›¾ç‰‡
        image_content = await image.read()
        essay_type_short = "small" if essay_type == "å°ä½œæ–‡" else "large"
        filename = f"essay_{year}_{essay_type_short}_{datetime.now().strftime('%Y%m%d%H%M%S')}.jpg"
        image_path = image_service.save_upload_file(image_content, filename)
        
        # 3. éªŒè¯å›¾ç‰‡
        if not image_service.validate_image(image_path):
            image_service.cleanup_file(image_path)
            raise HTTPException(status_code=400, detail="æ— æ•ˆçš„å›¾ç‰‡æ–‡ä»¶")
        
        # 4. ä½¿ç”¨AIè¿›è¡ŒOCRè¯†åˆ«
        print(f"[API] å¼€å§‹OCRè¯†åˆ«ä½œæ–‡å›¾ç‰‡")
        original_text = ai_service.image_to_text(image_path)
        
        # 5. è¿”å›è¯†åˆ«ç»“æœå’Œå¿…è¦çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        return {
            "original_text": original_text,
            "essay_image_path": image_path,  # ä¿å­˜è·¯å¾„ä¾›åç»­ä¼˜åŒ–ä½¿ç”¨
            "topic": f"{year}å¹´{essay_type}",
            "topic_image_path": topic_data.get('é¢˜ç›®å›¾ç‰‡è·¯å¾„', ''),
            "reference_essay": topic_data['å‚è€ƒèŒƒæ–‡']
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"OCRè¯†åˆ«å¤±è´¥: {str(e)}")


@router.post("/essays/analyze", response_model=EssayAnalysisResponse)
async def analyze_essay(request_data: Dict[str, Any] = Body(...)):
    """
    ç¬¬äºŒæ­¥ï¼šä¼˜åŒ–ä½œæ–‡
    æ¥æ”¶OCRè¯†åˆ«çš„æ–‡å­—ï¼Œç»“åˆé¢˜ç›®å›¾ç‰‡å’ŒèŒƒæ–‡è¿›è¡Œä¼˜åŒ–
    """
    try:
        # ä»è¯·æ±‚ä¸­æå–æ•°æ®
        year = request_data.get('year')
        essay_type = request_data.get('essay_type')
        original_text = request_data.get('original_text')
        topic_image_path = request_data.get('topic_image_path')
        reference_essay = request_data.get('reference_essay')
        
        if not all([year, essay_type, original_text, reference_essay]):
            raise HTTPException(status_code=400, detail="ç¼ºå°‘å¿…éœ€å‚æ•°")
        
        # ä½¿ç”¨optimize_essayæ–¹æ³•ï¼ˆå¸¦é¢˜ç›®å›¾ç‰‡çš„ä¼˜åŒ–ï¼‰
        print(f"[API] ä½¿ç”¨æ–‡å­—ç‰ˆåŸæ–‡ + é¢˜ç›®å›¾ç‰‡è¿›è¡Œä¼˜åŒ–")
        optimization_result = ai_service.optimize_essay(
            topic_image_path=topic_image_path,
            reference=reference_essay,
            original=original_text,
            essay_type=essay_type
        )
        
        # éªŒè¯ç»“æ„
        is_valid = ai_service.validate_structure(optimization_result)
        if not is_valid:
            print("[API] [WARNING] è¿”å›ç»“æ„éªŒè¯å¤±è´¥ï¼Œä½†ç»§ç»­è¿”å›æ•°æ®")
        
        # ç¡®ä¿åŸæ–‡è¢«åŒ…å«åœ¨ç»“æœä¸­
        if 'original_text' not in optimization_result:
            optimization_result['original_text'] = original_text
        
        # æå–è¯„åˆ†ä¿¡æ¯
        score_info = optimization_result.get('score', {'level': 'æœªè¯„åˆ†', 'points': 0})
        
        # è¿”å›å®Œæ•´ç»“æœ
        return {
            "topic": f"{year}å¹´{essay_type}",
            "topic_image_path": topic_image_path,
            "reference_essay": reference_essay,
            "original_text": optimization_result.get('original_text', original_text),
            "score": score_info,
            "optimized_text": optimization_result.get('optimized_text', ''),
            "suggestions": optimization_result.get('suggestions', {})
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¼˜åŒ–å¤±è´¥: {str(e)}")

@router.post("/essays/save")
def save_analysis(request_data: Dict[str, Any] = Body(...)):
    """
    ä¿å­˜åˆ†æç»“æœä¸ºmarkdownæ–‡ä»¶
    """
    try:
        year = request_data.get('year')
        data = request_data.get('data')
        # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆç»Ÿä¸€åˆ° data root ä¸‹çš„ study-helper/output/essaysï¼‰
        from config import OUTPUT_DIR
        output_dir = OUTPUT_DIR / "essays"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"essay_analysis_{year}_{timestamp}.md"
        file_path = output_dir / filename
        
        # è·å–æ‰“åˆ†ä¿¡æ¯
        score = data.get('score', {})
        score_text = ""
        if score:
            score_text = f"\n**è¯„åˆ†**: {score.get('points', 0)}åˆ† ({score.get('level', 'æœªè¯„åˆ†')})\n"
        
        # ç”Ÿæˆmarkdownå†…å®¹
        md_content = f"""# è‹±è¯­ä½œæ–‡åˆ†ææŠ¥å‘Š

**å¹´ä»½**: {year}
**ä½œæ–‡ç±»å‹**: {data.get('essay_type', '')}
{score_text}**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

---

## ğŸ“ é¢˜ç›®

{data.get('topic', '')}

---

## ğŸ“š å‚è€ƒèŒƒæ–‡

```
{data.get('reference_essay', '')}
```

---

## ğŸ“Š ä½œæ–‡å¯¹æ¯”

### åŸæ–‡

```
{data.get('original_text', '')}
```

### ä¼˜åŒ–å

```
{data.get('optimized_text', '')}
```

---

## ğŸ’¡ ä¿®æ”¹å»ºè®®

### 1. é¢˜æ„ç¬¦åˆåº¦

"""
        
        # å…¼å®¹ topic_complianceï¼ˆæ–°ï¼‰å’Œ topic_relevanceï¼ˆæ—§ï¼‰
        suggestions = data.get('suggestions', {})
        topic_content = suggestions.get('topic_compliance') or suggestions.get('topic_relevance', [])
        if isinstance(topic_content, list) and topic_content:
            for item in topic_content:
                md_content += f"- {item}\n"
        elif isinstance(topic_content, str) and topic_content:
            md_content += f"{topic_content}\n"
        else:
            md_content += "æ— å»ºè®®\n"
        
        md_content += "\n### 2. æ‹¼å†™é”™è¯¯\n\n"
        
        spelling_errors = suggestions.get('spelling_errors', [])
        if spelling_errors:
            for error in spelling_errors:
                md_content += f"- {error}\n"
        else:
            md_content += "æ— æ‹¼å†™é”™è¯¯\n"
        
        md_content += "\n### 3. è¯­æ³•é”™è¯¯\n\n"
        
        grammar_errors = suggestions.get('grammar_errors', [])
        if grammar_errors:
            for error in grammar_errors:
                md_content += f"- {error}\n"
        else:
            md_content += "æ— è¯­æ³•é”™è¯¯\n"
        
        md_content += "\n### 4. å•è¯ä¼˜åŒ–\n\n"
        
        word_opts = suggestions.get('word_optimization', [])
        if word_opts:
            for opt in word_opts:
                md_content += f"- {opt}\n"
        else:
            md_content += "æ— éœ€ä¼˜åŒ–\n"
        
        md_content += "\n### 5. å¥å¼ä¼˜åŒ–\n\n"
        
        sentence_opts = suggestions.get('sentence_optimization', [])
        if sentence_opts:
            for opt in sentence_opts:
                md_content += f"- {opt}\n"
        else:
            md_content += "æ— éœ€ä¼˜åŒ–\n"
        
        md_content += "\n### 6. ç»“æ„ä¼˜åŒ–\n\n"
        
        structure_opt = suggestions.get('structure_optimization', [])
        if isinstance(structure_opt, list) and structure_opt:
            for opt in structure_opt:
                md_content += f"- {opt}\n"
        elif isinstance(structure_opt, str) and structure_opt:
            md_content += f"{structure_opt}\n"
        else:
            md_content += "æ— éœ€ä¼˜åŒ–\n"
        
        md_content += "\n\n---\n\n*è¯¥æŠ¥å‘Šç”±Study Helperè‡ªåŠ¨ç”Ÿæˆ*\n"
        
        # ä¿å­˜æ–‡ä»¶
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(md_content)
        
        return {
            "message": "åˆ†ææŠ¥å‘Šå·²ä¿å­˜",
            "file_path": str(file_path)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¿å­˜å¤±è´¥: {str(e)}")

